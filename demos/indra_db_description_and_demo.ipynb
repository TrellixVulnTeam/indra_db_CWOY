{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The INDRA Database: Description and Demos\n",
    "\n",
    "This notebook walks through some of the basic structure of the INDRA Database, and then works through some use-case examples. It is generally assumed for the purposes of this notebook (unless otherwise stated), that the user has direct access to the database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------\n",
    "\n",
    "## The Need-to-knows of INDRA\n",
    "\n",
    "As the name suggests, this database is built using the tools of INDRA, and in turn it can be used to help with many uses of INDRA. It is thus valuable to go over some key features of the INDRA toolbox.\n",
    "\n",
    "### The INDRA Statement\n",
    "The bread and butter of the INDRA Database, and of INDRA itself, is the INDRA Statement, which is described extensively [here](file:///home/patrick/Workspace/indra/doc/_build/html/modules/statements.html). These Statements provide a robust and fairly extensible format for representing mechanistic interactions as Python objects. For the purposes of this tutorial, it is essential to know that Statements:\n",
    "- Have a **type**, for example:\n",
    "    - Phosphorylation\n",
    "    - Complex\n",
    "- Have **agents**, which in turn have some **db refs**, for example:\n",
    "    - MEK has the Famplex db ref id MEK\n",
    "    - Vemurafenib is an agent with the db refs for a CHEBI id \"CHEBI:63637\" and a ChEMBL id \"ChEMBL1229517\"\n",
    "    \n",
    "Most have two agents, a subject and an object, for example:\n",
    "- `Phosphorylation(MEK(), ERK())`\n",
    "- `Inhibition(Vemurafenib(), BRAF())`\n",
    "\n",
    "but there are some types of Statement that are notable exceptions:\n",
    "- Complexes (any number of agents)\n",
    "- Auto-Phospohorylations (one agent)\n",
    "\n",
    "### Sources of INDRA Statements\n",
    "INDRA has implemented tools for loading and generating these Statements from several sources. Here, the key points to recall are that:\n",
    "- INDRA can draw from both from **machine reading systems** such as REACH, and from **mechanism databases**, such as Pathway Commons\n",
    "- For readings, INDRA also provides the groundwork for **running certain readers at massive scales**, fairly easily using AWS Batch.\n",
    "- The results from these sources, especially when combined, **contain a lot of duplicate and closely related information**.\n",
    "\n",
    "### Preassembly of INDRA Statements\n",
    "To build useful models from all these sources, INDRA supplies tools to perform what is call \"preasssembly\" (what you do before \"assembling\" your model), in which:\n",
    "- grounding is regularized (fixes agent db refs), as are protein sites and agent names.\n",
    "- the **redunant information between sources is merged, *with the original source information and evidence preserved*, into a distilled set of unique mechanisms**\n",
    "- the relationship between similar mechanistic information is recorded, such that a more general Statement, such as `Phosphorylation(MEK(), ERK())` can be identified as generalizing `Phosphorylation(MAP2K1(), MAPK1())`.\n",
    "- **Such Preassembled Statements can be uniquely identified by a hash generated from their contents**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------\n",
    "\n",
    "## The Structure of the Database\n",
    "\n",
    "<img src=\"db_basic_structure.png\">\n",
    "\n",
    "The INDRA Database is made up of several tables. There are 4 core groups, shown in the three cylinders and one box above:\n",
    "- **Sources:** Keep track of the content that we read, and the readings of that content, including titles, abstracts, and full texts from various sources. Also keep some metadata on the databases we import.\n",
    "    - `text_refs`,\n",
    "    - `text_content`\n",
    "    - `reading`\n",
    "    - `db_info`\n",
    "- **Raw Statements:** Store all the statements extracted from all the sources, as-is.\n",
    "    - `raw_statements`\n",
    "- **Preassembled Statements:** Here are stored the cleaned, distilled, and relation-mapped statements.\n",
    "    - `raw_unique_links`\n",
    "    - `pa_statements`\n",
    "    - `pa_agents`\n",
    "    - `pa_support_links`\n",
    "- **Materialized Views:** Pre-calculate certain queries for rapid retrieval.\n",
    "    - `pa_meta`\n",
    "    - `fast_raw_pa_link`\n",
    "    - `pa_stmt_src`\n",
    "    - `reading_ref_link`\n",
    "\n",
    "There are many more tables, however there are in general not going to be essential in this demo. Here is a diagram of the database schema, not including the materialized views (which are not really part of the schema), with the major groupings colorcoded. Green indicates *sources*, orange indicates *raw statements*, and blue indicates *preassembled statements*. Each line indicates the presence of a foreign-key link.\n",
    "\n",
    "<img src=\"indra_db.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "\n",
    "## Demos\n",
    "\n",
    "What follows are some demonstrations of the ways you can access the database, at various different levels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Low level access\n",
    "\n",
    "To access and manage the database at the lowest level, the `DatabaseManager` class, from `indra_db.managers.database_manager` is used. You need to have access to the database, hosted on AWS RDS, configured in a config file (documented elsewhere). Here is an example of getting a piece of content from the database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_content:\n",
      "\tinsert_date: 2018-05-18 17:45:23.406707\n",
      "\ttext_type: abstract\n",
      "\tsource: pubmed\n",
      "\tid: 20202368\n",
      "\tlast_updated: None\n",
      "\tcontent: [not shown]\n",
      "\tformat: text\n",
      "\ttext_ref_id: 28416337\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from indra_db.util import get_db, unpack\n",
    "\n",
    "# Get a handle to the database\n",
    "db = get_db('primary')\n",
    "\n",
    "# Get a piece of text content that is an abstract. Everything after the first argument is a condition.\n",
    "tc = db.select_one(db.TextContent, db.TextContent.text_type == 'abstract')\n",
    "print(tc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The actual content is not shown so that the metadata is readable. But you can look at the content by just printing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visual expertise induces changes in neural processing for many different domains of expertise. However, it is unclear how expertise effects for different domains of expertise are related. In the present fMRI study, we combine large-scale univariate and multi-voxel analyses to contrast the expertise-related neural changes associated with two different domains of expertise, bird expertise (ornithology) and mineral expertise (mineralogy). Results indicated distributed expertise-related neural changes, with effects for both domains of expertise in high-level visual cortex and effects for bird expertise even extending to low-level visual regions and the frontal lobe. Importantly, a multivariate generalization analysis showed that effects in high-level visual cortex were specific to the domain of expertise. In contrast, the neural changes in the frontal lobe relating to expertise showed significant generalization, signaling the presence of domain-independent expertise effects. In conclusion, expertise is related to a combination of domain-specific and domain-general changes in neural processing.\n"
     ]
    }
   ],
   "source": [
    "print(unpack(tc.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the content must be `unpack`ed. This is because we store compressed binary on the database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can get a raw statement from a pmcid by using the `db.link` feature, which uses a networkx graph to construct the necessary joins on your behalf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_stmt_rows = db.select_all(db.RawStatements, db.TextRef.pmcid == 'PMC4055958',\n",
    "                              *db.link(db.RawStatements, db.TextRef))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look at some of these objects that were returned. The `repr` of the object is not especially informative:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<indra_db.managers.database_manager.DatabaseManager.__init__.<locals>.RawStatements at 0x7f5e5d6a55c0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_stmt_rows[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However you can, as shown above, `print` the object. Again, the more verbose column, the `json` encoding of the Statement is not printed in this display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw_statements:\n",
      "\tcreate_date: 2019-05-31 14:06:53.451841\n",
      "\tindra_version: 1.12.0-8d138ebe7e70fefdb7edde1769c0c8bd8cb91526\n",
      "\treading_id: 10100019060322\n",
      "\tsource_hash: 1446941550084421822\n",
      "\tmk_hash: -35673697574246703\n",
      "\tbatch_id: 533420918\n",
      "\tid: 10341408\n",
      "\tjson: [not shown]\n",
      "\ttype: IncreaseAmount\n",
      "\tdb_info_id: None\n",
      "\ttext_hash: -3758986799612051399\n",
      "\tuuid: 6f59cf8d-0210-448b-89de-f5363479e116\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(raw_stmt_rows[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'{\"type\": \"IncreaseAmount\", \"subj\": {\"name\": \"MDMA\", \"db_refs\": {\"PUBCHEM\": \"1615\", \"TEXT\": \"MDMA\"}}, \"obj\": {\"name\": \"Ca\", \"db_refs\": {\"PUBCHEM\": \"271\", \"TEXT\": \"Ca\"}}, \"belief\": 1, \"evidence\": [{\"source_api\": \"reach\", \"text\": \"MDMA induced an increase in basal cytosolic Ca 2+ levels, measured after drug washout.\", \"annotations\": {\"found_by\": \"amount_1\", \"agents\": {\"coords\": [[0, 4], [44, 46]]}}, \"epistemics\": {\"direct\": false, \"section_type\": null}, \"text_refs\": {\"PMID\": \"18050169\"}, \"source_hash\": 1446941550084421822}], \"id\": \"6f59cf8d-0210-448b-89de-f5363479e116\"}'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_stmt_rows[0].json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The details of this code are not essential, however you can see that we get a lot of statements from this fulltext, and that there are two different readings producting this content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10100019060322\n",
      "\t IncreaseAmount(MDMA(), Ca())\n",
      "\t DecreaseAmount(Ca(), CYCS())\n",
      "\t Phosphorylation(tpa-1(), SLC6A3())\n",
      "\t Complex(METH(), MDMA())\n",
      "\t Activation(vesicular monoamine transporters(), transport())\n",
      "\t Activation(MDMA(), ROS())\n",
      "\t Activation(METH(), ROS())\n",
      "\t Activation(MDMA(), ROS())\n",
      "\t Activation(MDMA(), ROS())\n",
      "\t Activation(METH(), DCF())\n",
      "\t ... and 51 more!\n",
      "20300019060322\n",
      "\t Phosphorylation(None, SLC6A3())\n",
      "\t Complex(NOS1(), serotonin())\n",
      "\t Complex(PTPN5(), FOXM1())\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from indra_db.util import get_statement_object\n",
    "\n",
    "# Make a dict of lists keyed by reading id (all statements grouped by reading)\n",
    "raw_stmts_by_rid = defaultdict(list)\n",
    "for row in raw_stmt_rows:\n",
    "    raw_stmts_by_rid[row.reading_id].append(row)\n",
    "\n",
    "# Print a sampling of the statements\n",
    "for rid, some_rows in raw_stmts_by_rid.items():\n",
    "    print(rid)\n",
    "    for row in some_rows[:10]:\n",
    "        print('\\t', get_statement_object(row))\n",
    "    if len(some_rows) > 10:\n",
    "        print(f\"\\t ... and {len(some_rows) - 10} more!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also search for pa_statements by linking further from the raw statement to the preassembled statements, through the `raw_unique_links`, which is again handled tidily by the `db.link` feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw_unique_links.pa_stmt_mk_hash = pa_statements.mk_hash\n",
      "raw_unique_links.raw_stmt_id = raw_statements.id\n",
      "raw_statements.reading_id = reading.id\n",
      "reading.text_content_id = text_content.id\n",
      "text_content.text_ref_id = text_ref.id\n"
     ]
    }
   ],
   "source": [
    "for link in db.link(db.PAStatements, db.TextRef):\n",
    "    print(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I found 49 preassmebled statements.\n",
      "\n",
      "Here's a sample:\n",
      "Phosphorylation(PKC(), SLC6A3())\n",
      "Complex(serotonin(), NOS1())\n",
      "Activation(CHRN(), pyraclofos())\n",
      "Activation(NOS1(), nitric oxide())\n",
      "Activation(3,4-methylenedioxymethamphetamine(), ROS1())\n",
      "Activation(METH(), DCF())\n",
      "Inhibition(MEM(), alpha7 nAChR())\n",
      "Activation(METH(), dopamine())\n",
      "DecreaseAmount(calcium(2+)(), CYCS())\n",
      "Activation(3,4-methylenedioxymethamphetamine(), calcium(2+)())\n"
     ]
    }
   ],
   "source": [
    "pa_stmt_rows = db.select_all(db.PAStatements, db.TextRef.pmcid == 'PMC4055958', \n",
    "                             *db.link(db.PAStatements, db.TextRef))\n",
    "print(f\"I found {len(pa_stmt_rows)} preassmebled statements.\\n\")\n",
    "\n",
    "# Print some samples.\n",
    "print(\"Here's a sample:\")\n",
    "for row in pa_stmt_rows[:10]:\n",
    "    print(get_statement_object(row))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the redundant Statements have been collapse.\n",
    "\n",
    "As a demonstration, we could use the results of this search to find more paper ids for papers involving similar mechanisms. This works because each preassembled statment is supported by multiple raw statements, in general from multiple papers. *Note that the preassembled statements are identified by a hash of what's called a matches-key, or `mk_hash`.* These are a re-producable value which uniquely identifies a preassembled statement by the information it represents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We found 4374 text refs with related mechanisms!\n",
      "\n",
      "PMID: 20047071    PMCID: None\n",
      "PMID: 24275851    PMCID: PMC3817602\n",
      "PMID: 23578024    PMCID: PMC3914398\n",
      "PMID: 9182590     PMCID: None\n",
      "PMID: 24549364    PMCID: PMC4138306\n",
      "PMID: 24875574    PMCID: PMC4203735\n",
      "PMID: 23959639    PMCID: PMC3859705\n",
      "PMID: 16359614    PMCID: None\n",
      "PMID: 19758695    PMCID: None\n",
      "PMID: 27047180    PMCID: PMC4774759\n"
     ]
    }
   ],
   "source": [
    "text_ref_rows = db.select_all(db.TextRef, db.PAStatements.mk_hash.in_({row.mk_hash for row in pa_stmt_rows}),\n",
    "                              *db.link(db.PAStatements, db.TextRef))\n",
    "print(f\"We found {len(text_ref_rows)} text refs with related mechanisms!\\n\")\n",
    "\n",
    "# Print a sample of the pmids and pmcids for each ref.\n",
    "for row in text_ref_rows[:10]:\n",
    "    print(f\"PMID: {str(row.pmid):10}  PMCID: {row.pmcid}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can of course also search for statements involving certain entities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for statements with agents whose 'NAME' is 'BRAF', where the agent is the object, where the\n",
    "# Statement is an Inhibition.\n",
    "inhibits_braf_rows = db.select_all(db.PAStatements, db.PAStatements.mk_hash == db.PAAgents.stmt_mk_hash,\n",
    "                                   db.PAAgents.db_id == 'BRAF', db.PAAgents.db_name == 'NAME',\n",
    "                                   db.PAAgents.role == 'OBJECT', db.PAStatements.type == 'Inhibition')\n",
    "print(f\"I found {len(inhibits_braf_rows)} statements about the inhibition of BRAF!\\n\")\n",
    "\n",
    "# Print a sample\n",
    "print(\"Here's a sample:\")\n",
    "for row in inhibits_braf_rows[:10]:\n",
    "    print(get_statement_object(row))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The indra_db client API\n",
    "\n",
    "This is a rather cumbersome way to look for statements, and moreover there are two problems with this result:\n",
    "1. The raw evidence is not included.\n",
    "2. You can only query by one agent, when what you often want is to search for _both_ entities in a relationship.\n",
    "\n",
    "To address this problem, a higher-level API was developed, which can be found in the `indra_db.client`, in particular `indra_db.client.optimized`. These tools allow for fully-formed (modulo support links) statements to be rapidly loaded from the database. Note: *This API makes use of the materialized views to speed queries.*\n",
    "\n",
    "The principle function implemented in the client allows you to search and retrieve preassembled statements based on their entities and type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from indra.statements import Statement\n",
    "from indra_db import client as dbc\n",
    "\n",
    "# Look for a statement with two agents, a subject with the Famplex grounding of \"MEK\", and an object\n",
    "# with the Famplex grounding of \"ERK\", that is of type \"Phosphorylation\", and return only at most 5 evidence\n",
    "# for each pa statement.\n",
    "results = dbc.get_statement_jsons_from_agents([('SUBJECT', 'MEK', 'FPLX'), ('OBJECT', 'ERK', 'FPLX')],\n",
    "                                              stmt_type='Phosphorylation', ev_limit=5)\n",
    "\n",
    "# Print the keys.\n",
    "print(\"The result has the following keys:\", set(results.keys()))\n",
    "\n",
    "# Summarize the results.\n",
    "print(f\"There is {results['total_evidence']} 'total_evidence' available, \"\n",
    "      f\"and {results['evidence_returned']} ('evidence_returned') were returned \"\n",
    "      f\"for {len(results['statements'])} Statements.\")\n",
    "\n",
    "# Print some samples\n",
    "for stmt_json in results['statements'].values():\n",
    "      print(Statement._from_json(stmt_json))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though we were fairly specific in our query, there are still variations in the details. Soon we will make it possible to search by the modifications and mutations.\n",
    "\n",
    "The json for each of these statements contains extensive and rich information, for example let us inspect the very last json in our list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(stmt_json, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use the client to get such Statement jsons by using the `mk_hash`. This could be useful, for an example in this case, to get the rest of the evidence for that first, generic statement that was returned (`Phosphorylation(MEK(), ERK())`). In fact, we don't even need to use that object, we could just declare a Statement with those attributes and look up evidence for it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from indra.statements import Phosphorylation, Agent\n",
    "\n",
    "stmt = Phosphorylation(Agent('MEK', db_refs={'FPLX': 'MEK'}), Agent('ERK', db_refs={'FPLX': 'ERK'}))\n",
    "print(\"Our brand-new off-the-lot Statement:\", stmt)\n",
    "\n",
    "# Show that the hash is the same\n",
    "print(\"You can see the hashes are the same: new \", stmt.get_hash(), 'vs old', list(results['statements'].keys())[0])\n",
    "\n",
    "# And we can look it up on the database\n",
    "one_stmt_result = dbc.get_statement_jsons_from_hashes([stmt.get_hash()])\n",
    "\n",
    "stmt_from_db = Statement._from_json(list(results['statements'].values())[0])\n",
    "\n",
    "print()\n",
    "print(\"The statement retrieved from the database:\", stmt_from_db)\n",
    "print(\"\\nEvidence text and source for this statement:\")\n",
    "for ev in stmt_from_db.evidence:\n",
    "    print()\n",
    "    print('source:', ev.source_api)\n",
    "    print('text:', ev.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Even higher \n",
    "- Describe split between UI and API\n",
    "- Rest api from agents\n",
    "- from hash\n",
    "- submit curation\n",
    "\n",
    "## UI\n",
    "- From Agents\n",
    "\n",
    "## indrabot\n",
    "- a few screenshots\n",
    "\n",
    "## Plug for INDRA Google\n",
    "- simple one-bar interface\n",
    "- ablity to ask basic follow-up filtering/extending questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
